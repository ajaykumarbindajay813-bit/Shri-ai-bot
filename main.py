from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from huggingface_hub import InferenceClient
import os

app = FastAPI()

# CORS setup
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Hugging Face Access Token - ‡§á‡§∏‡•á ‡§∏‡•Ä‡§ß‡•á ‡§ï‡•ã‡§° ‡§Æ‡•á‡§Ç ‡§® ‡§°‡§æ‡§≤‡•á‡§Ç
# ‡§¨‡§≤‡•ç‡§ï‡§ø environment variable ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç
HF_TOKEN = os.getenv("HUGGING_FACE_TOKEN")

# Hugging Face Inference Client - ‡§Ø‡§π‡§æ‡§Å ‡§Ö‡§™‡§®‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§°‡§æ‡§≤‡•á‡§Ç
client = InferenceClient(model="google/gemma-2b", token=HF_TOKEN)

# Simple cache
cache = {}

@app.post("/chat")
async def chat(request: Request):
    data = await request.json()
    user_message = data.get("message", "").strip()

    if not user_message:
        return {"reply": "‡§ï‡•Å‡§õ ‡§§‡•ã ‡§≤‡§ø‡§ñ‡•ã, ‡§Æ‡•à‡§Ç ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Å üôÇ"}

    # Cache check
    if user_message in cache:
        return {"reply": cache[user_message]}
    
    # ‡§Ø‡§¶‡§ø ‡§ü‡•ã‡§ï‡§® ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ ‡§§‡•ã ‡§è‡§∞‡§∞ ‡§≠‡•á‡§ú‡•á‡§Ç
    if not HF_TOKEN:
        return {"reply": "Error: Hugging Face Token is not set. Please set the HUGGING_FACE_TOKEN environment variable."}

    try:
        # Hugging Face ‡§Æ‡•â‡§°‡§≤ ‡§∏‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡§æ
        response = client.text_generation(
            prompt=user_message,
            max_new_tokens=150,
            temperature=0.7,
            truncate=True
        )

        reply = response.strip()
        cache[user_message] = reply
        return {"reply": reply}

    except Exception as e:
        return {"reply": f"‡§Æ‡§æ‡§´‡§º ‡§ï‡§∞‡§®‡§æ, ‡§ï‡•Å‡§õ ‡§¶‡§ø‡§ï‡•ç‡§ï‡§§ ‡§π‡•à: {e}"}

# Serve index.html - ‡§á‡§∏‡•á ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§Ç‡§§ ‡§Æ‡•á‡§Ç ‡§∞‡§ñ‡•á‡§Ç
app.mount("/", StaticFiles(directory=".", html=True), name="static")
